{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebaabbd4",
   "metadata": {},
   "source": [
    "# Optimal Lag Selection based on MRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ad9757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: \n",
    "\n",
    "# Part I: MRMR criterion selection\n",
    "\n",
    "# Author: Shilin Zhang\n",
    "\n",
    "# Problem: Finding a robust way of choosing an optimal lag on mutiple kinds of time series regression models\n",
    "\n",
    "# Method: Minimize Redundancy Maxmize Relevance, Genetic Algorithm, Forwardstep selection\n",
    "\n",
    "# Measurement: correlation coefficient, mutual information, partial correlation\n",
    "\n",
    "# Related papers: \n",
    "# Comprehensive study of feature selection methods to solve multicollinearity problem according to evaluation criteria - Alexandr Katrutsa\n",
    "# Effective Global Approaches for Mutual Information Based Feature Selection - Nguyen Xuan Vinh\n",
    "\n",
    "# Program Start Date: June 1st 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90945717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import pingouin as pg\n",
    "from functools import reduce\n",
    "\n",
    "from numpy.random import randint\n",
    "from numpy.random import rand\n",
    "np.random.seed(10)\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e81d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Load the data set from local file\n",
    "\n",
    "startdate = '2012-04-01'\n",
    "enddate = '2022-06-01'\n",
    "datasource = 'SPY'\n",
    "\n",
    "data = yf.download(datasource,start = startdate,end = enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ede718",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Close'\n",
    "train_test_ratio = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47740577",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-04-02</th>\n",
       "      <td>140.639999</td>\n",
       "      <td>142.210007</td>\n",
       "      <td>140.360001</td>\n",
       "      <td>141.839996</td>\n",
       "      <td>116.762009</td>\n",
       "      <td>151741100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-03</th>\n",
       "      <td>141.639999</td>\n",
       "      <td>141.880005</td>\n",
       "      <td>140.429993</td>\n",
       "      <td>141.259995</td>\n",
       "      <td>116.284554</td>\n",
       "      <td>155806700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-04</th>\n",
       "      <td>140.220001</td>\n",
       "      <td>140.339996</td>\n",
       "      <td>139.339996</td>\n",
       "      <td>139.860001</td>\n",
       "      <td>115.132072</td>\n",
       "      <td>146896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-05</th>\n",
       "      <td>139.380005</td>\n",
       "      <td>140.199997</td>\n",
       "      <td>139.259995</td>\n",
       "      <td>139.789993</td>\n",
       "      <td>115.074417</td>\n",
       "      <td>137439400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-09</th>\n",
       "      <td>138.029999</td>\n",
       "      <td>139.839996</td>\n",
       "      <td>137.839996</td>\n",
       "      <td>138.220001</td>\n",
       "      <td>113.782036</td>\n",
       "      <td>127555900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-24</th>\n",
       "      <td>392.559998</td>\n",
       "      <td>395.149994</td>\n",
       "      <td>386.959991</td>\n",
       "      <td>393.890015</td>\n",
       "      <td>392.195831</td>\n",
       "      <td>91448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-25</th>\n",
       "      <td>392.309998</td>\n",
       "      <td>399.450012</td>\n",
       "      <td>391.890015</td>\n",
       "      <td>397.369995</td>\n",
       "      <td>395.660858</td>\n",
       "      <td>91472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-26</th>\n",
       "      <td>398.670013</td>\n",
       "      <td>407.040009</td>\n",
       "      <td>398.450012</td>\n",
       "      <td>405.309998</td>\n",
       "      <td>403.566711</td>\n",
       "      <td>82168300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>407.910004</td>\n",
       "      <td>415.380005</td>\n",
       "      <td>407.700012</td>\n",
       "      <td>415.260010</td>\n",
       "      <td>413.473907</td>\n",
       "      <td>84768700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>413.549988</td>\n",
       "      <td>416.459991</td>\n",
       "      <td>410.029999</td>\n",
       "      <td>412.929993</td>\n",
       "      <td>411.153931</td>\n",
       "      <td>95937000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2558 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2012-04-02  140.639999  142.210007  140.360001  141.839996  116.762009   \n",
       "2012-04-03  141.639999  141.880005  140.429993  141.259995  116.284554   \n",
       "2012-04-04  140.220001  140.339996  139.339996  139.860001  115.132072   \n",
       "2012-04-05  139.380005  140.199997  139.259995  139.789993  115.074417   \n",
       "2012-04-09  138.029999  139.839996  137.839996  138.220001  113.782036   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2022-05-24  392.559998  395.149994  386.959991  393.890015  392.195831   \n",
       "2022-05-25  392.309998  399.450012  391.890015  397.369995  395.660858   \n",
       "2022-05-26  398.670013  407.040009  398.450012  405.309998  403.566711   \n",
       "2022-05-27  407.910004  415.380005  407.700012  415.260010  413.473907   \n",
       "2022-05-31  413.549988  416.459991  410.029999  412.929993  411.153931   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2012-04-02  151741100  \n",
       "2012-04-03  155806700  \n",
       "2012-04-04  146896000  \n",
       "2012-04-05  137439400  \n",
       "2012-04-09  127555900  \n",
       "...               ...  \n",
       "2022-05-24   91448800  \n",
       "2022-05-25   91472900  \n",
       "2022-05-26   82168300  \n",
       "2022-05-27   84768700  \n",
       "2022-05-31   95937000  \n",
       "\n",
       "[2558 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7dc7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function spliting train test set \n",
    "\n",
    "def train_test_split(data, train_test_ratio):\n",
    "    \n",
    "    split_point = round(data.shape[0] * train_test_ratio)\n",
    "    training_data = data.iloc[0:split_point,:]\n",
    "    testing_data = data.iloc[split_point: ,:]\n",
    "    \n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5197039",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ca441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the target to avoid the data leakage\n",
    "\n",
    "def data_shift(train,target):\n",
    "    data_shifted = train.shift()\n",
    "    data_preprocessed = pd.concat([data_shifted,train[target]], axis=1)\n",
    "    data_preprocessed.dropna(inplace=True)\n",
    "    return data_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf790a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Setting\n",
    "\n",
    "# maximum lag\n",
    "max_lag = 30\n",
    "\n",
    "# length of an individual\n",
    "n_d = data.shape[1] * max_lag\n",
    "\n",
    "# number of generation\n",
    "n_g = 300\n",
    "# number of population\n",
    "n_p = 100\n",
    "# crossover prob\n",
    "p_c = 0.85\n",
    "# mutation prob\n",
    "p_m = 0.05\n",
    "\n",
    "# parameter for negentropy estimation\n",
    "a_1 = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57711fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the feature space\n",
    "\n",
    "def feature_space_generator(data, max_lag):\n",
    "    X = np.empty((data.shape[0],0))\n",
    "    y = pd.DataFrame(data.iloc[:,-1])\n",
    "    for lag in range(0,max_lag):\n",
    "       X = np.concatenate((X, data.iloc[:,:-1].shift(lag)), axis = 1) \n",
    "    Xy = pd.DataFrame(np.concatenate((X, y), axis = 1)).dropna()\n",
    "    X = pd.DataFrame(Xy.iloc[:,:-1])\n",
    "    y = pd.DataFrame(Xy.iloc[:,-1])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a2367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function normalizing of sim and rel matrix\n",
    "\n",
    "def normalization(Q):\n",
    "    df = pd.DataFrame(Q)\n",
    "    cols = df.columns.values.tolist()\n",
    "    df_new = df.divide(df[cols].values.sum())\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b026860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_problem_generator(X, y, sim, rel):\n",
    "    if sim == 'correl':\n",
    "        Q = abs(np.corrcoef(X.T))\n",
    "    elif sim == 'mi':\n",
    "        Q = np.zeros((X.shape[1],X.shape[1]))\n",
    "        for i in range(0,X.shape[1]):\n",
    "            for j in range(0,X.shape[1]):\n",
    "                if(i<j):\n",
    "                    Q[i,j] = mutual_info_score(X.iloc[:,i],X.iloc[:,j])\n",
    "                elif(i>j):\n",
    "                    Q[i,j] = Q[j,i]\n",
    "    if rel == 'correl':\n",
    "        b = abs(pd.DataFrame(np.concatenate((X,y),axis = 1)).corr().iloc[:-1,-1])\n",
    "    elif rel == 'mi':\n",
    "        b = np.zeros((X.shape[1],1))\n",
    "        for i in range(0,X.shape[1]):\n",
    "            b[i,0] = mutual_info_score(X.iloc[:,i],y.iloc[:,0])\n",
    "    elif rel == 'pcor':\n",
    "        b = abs(pd.DataFrame(np.concatenate((X,y),axis = 1)).pcorr()).iloc[:-1,-1]\n",
    "    \n",
    "    #Q = np.array(normalization(Q))\n",
    "    b = np.array(normalization(b)).tolist()\n",
    "    b = reduce(lambda x, y: x + y, b)\n",
    "    b = np.array(b)\n",
    "    return Q,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ed035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic algorithm search for optimization problem\n",
    "\n",
    "# Objective function\n",
    "\n",
    "# x is the binary/gene list shows the presence or absence of the feature in feature subset\n",
    "\n",
    "def obj(x, Q, b):\n",
    "    a = pd.DataFrame(x)\n",
    "    sim_value = np.dot(np.dot(a.T,Q),a)[0,0]\n",
    "    rel_value = np.dot(b.T,a)\n",
    "    score = sim_value - rel_value\n",
    "    return score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4370d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection\n",
    "\n",
    "def selection(pop, scores, k=3):\n",
    "    # first random selection\n",
    "    selection_ix = randint(len(pop))\n",
    "    for ix in randint(0, len(pop), k-1):\n",
    "        # check if better (e.g. perform a tournament)\n",
    "        if scores[ix] < scores[selection_ix]:\n",
    "            selection_ix = ix\n",
    "    return pop[selection_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05998370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossover two parents to create two children\n",
    "\n",
    "def crossover(p1, p2, r_cross):\n",
    "    # children are copies of parents by default\n",
    "    c1, c2 = p1.copy(), p2.copy()\n",
    "    # check for recombination\n",
    "    if rand() < r_cross:\n",
    "        # select crossover point that is not on the end of the string\n",
    "        pt = randint(1, len(p1)-2)\n",
    "        # perform crossover\n",
    "        c1 = p1[:pt] + p2[pt:]\n",
    "        c2 = p2[:pt] + p1[pt:]\n",
    "    return [c1, c2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17a5ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutation operator\n",
    "\n",
    "def mutation(bitstring, r_mut):\n",
    "    for i in range(len(bitstring)):\n",
    "        # check for a mutation\n",
    "        if rand() < r_mut:\n",
    "            # flip the bit\n",
    "            bitstring[i] = 1 - bitstring[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e56318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic algorithm\n",
    "\n",
    "def genetic_algorithm(objective, n_bits, n_iter, n_pop, r_cross, r_mut, Q, b):\n",
    "    # initial population of random bitstring\n",
    "    pop = [randint(0, 2, n_bits).tolist() for _ in range(n_pop)]\n",
    "    # keep track of best solution\n",
    "    best, best_eval = 0, objective(pop[0],Q, b)\n",
    "    # enumerate generations\n",
    "    for gen in range(n_iter):\n",
    "        # print(\"iteration: \" + str(gen + 1))\n",
    "        # evaluate all candidates in the population\n",
    "        scores = [objective(c,Q, b) for c in pop]\n",
    "        # check for new best solution\n",
    "        for i in range(n_pop):\n",
    "            if scores[i] < best_eval:\n",
    "                best, best_eval = pop[i], scores[i]\n",
    "                print(\"iteration: %d, number of features: %d, score: %.3f\" %(gen + 1, sum(pop[i]), scores[i]))\n",
    "        # select parents\n",
    "        selected = [selection(pop, scores) for _ in range(n_pop)]\n",
    "        # create the next generation\n",
    "        children = list()\n",
    "        for i in range(0, n_pop, 2):\n",
    "            # get selected parents in pairs\n",
    "            p1, p2 = selected[i], selected[i+1]\n",
    "            # crossover and mutation\n",
    "            for c in crossover(p1, p2, r_cross):\n",
    "                # mutation\n",
    "                mutation(c, r_mut)\n",
    "                # store for next generation\n",
    "                children.append(c)\n",
    "        # replace population\n",
    "        pop = children\n",
    "    return [best, best_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7089cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_list = ['correl','mi']\n",
    "rel_list = ['correl','mi','pcor']\n",
    "\n",
    "# Function selecting laged features based on mutiple criterions\n",
    "\n",
    "def multi_lag_selection(sim_list,rel_list,X,y):\n",
    "    best_list = []\n",
    "    score_list = []\n",
    "    for sim in sim_list:\n",
    "        for rel in rel_list:\n",
    "            print(sim,rel)\n",
    "            Q,b =  opt_problem_generator(X, y, sim, rel)\n",
    "            best, score = genetic_algorithm(obj, n_d, n_g, n_p, p_c, p_m, Q, b)\n",
    "            best_list.append(best)\n",
    "            score_list.append(score)\n",
    "    return best_list,score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31dbf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer bitstring of integer values to feature subset\n",
    "\n",
    "def feature_subset_generator(X,gene_list):\n",
    "    result = np.empty((X.shape[0],0))\n",
    "    n = 0\n",
    "    for i in gene_list:\n",
    "        if i == 1:\n",
    "            result = np.concatenate((result, pd.DataFrame(X.iloc[:,n])), axis = 1) \n",
    "        n  = n + 1\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ce96b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training or testing dataset\n",
    "\n",
    "def generate_list(X,y, best_list):\n",
    "    train_list = []\n",
    "    for i in best_list:\n",
    "        subset = feature_subset_generator(X,i)\n",
    "        train = pd.DataFrame(np.concatenate((subset, y), axis = 1))\n",
    "        train_list.append(train)\n",
    "    return train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b1696a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23524f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_result(train_list,test_list):\n",
    "    print('Result of Linear Regression')\n",
    "    RMSE_all = []\n",
    "    for i in range(0,len(train_list)):\n",
    "        print('Criterion ' + str(i+1) + ': ')\n",
    "        train = train_list[i]\n",
    "        test = test_list[i]\n",
    "            \n",
    "        train_x = train.iloc[:,:(train.shape[1] - 1)]\n",
    "        train_y = train.iloc[:,-1:]\n",
    "            \n",
    "        test_x = test.iloc[:,:(test.shape[1] - 1)]\n",
    "        test_y = test.iloc[:,-1:]\n",
    "            \n",
    "        regressor = LinearRegression()\n",
    "        model = TransformedTargetRegressor(regressor= regressor,\n",
    "                                        transformer = MinMaxScaler()\n",
    "                                        ).fit(train_x,train_y)\n",
    "        y_pred = model.predict(test_x)\n",
    "            \n",
    "        RMSE = (math.sqrt(mean_squared_error(y_pred, test_y)))\n",
    "        print(RMSE)\n",
    "        RMSE_all.append(RMSE)\n",
    "        \n",
    "    print(min(RMSE_all))\n",
    "\n",
    "    print(' ')\n",
    "    return RMSE_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a97039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_result(train_list,test_list):\n",
    "    print('Result of Random Forest')\n",
    "    RMSE_all = []\n",
    "    for i in range(0,len(train_list)):\n",
    "        print('Criterion ' + str(i+1) + ': ')\n",
    "        train = train_list[i]\n",
    "        test = test_list[i]\n",
    "            \n",
    "        train_x = train.iloc[:,:(train.shape[1] - 1)]\n",
    "        train_y = train.iloc[:,-1:]\n",
    "            \n",
    "        test_x = test.iloc[:,:(test.shape[1] - 1)]\n",
    "        test_y = test.iloc[:,-1:]\n",
    "            \n",
    "        regressor = RandomForestRegressor()\n",
    "        model = TransformedTargetRegressor(regressor= regressor,\n",
    "                                        transformer = MinMaxScaler()\n",
    "                                        ).fit(train_x,train_y)\n",
    "        y_pred = model.predict(test_x)\n",
    "            \n",
    "        RMSE = (math.sqrt(mean_squared_error(y_pred, test_y)))\n",
    "        print(RMSE)\n",
    "        RMSE_all.append(RMSE)\n",
    "        \n",
    "    print(min(RMSE_all))\n",
    "    print(' ')\n",
    "    return RMSE_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe30fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_result(train_list,test_list):\n",
    "    print('Result of elastic net')\n",
    "    RMSE_all = []\n",
    "    for i in range(0,len(train_list)):\n",
    "        print('Criterion ' + str(i+1) + ': ')\n",
    "\n",
    "        train = train_list[i]\n",
    "        test = test_list[i]\n",
    "            \n",
    "        train_x = train.iloc[:,:(train.shape[1] - 1)]\n",
    "        train_y = train.iloc[:,-1:]\n",
    "            \n",
    "        test_x = test.iloc[:,:(test.shape[1] - 1)]\n",
    "        test_y = test.iloc[:,-1:]\n",
    "            \n",
    "        model = ElasticNet()\n",
    "        # define grid\n",
    "        grid = dict()\n",
    "        grid['alpha'] = [0.0, 1.0, 10.0, 100.0]\n",
    "        grid['l1_ratio'] = [0.1,0.5,0.7,0.9,0.95,0.99,1]\n",
    "        # define search\n",
    "        search = GridSearchCV(model, grid, scoring='neg_mean_squared_error')\n",
    "        best = search.fit(train_x,train_y)\n",
    "        best_model = ElasticNet(l1_ratio = best.best_params_.get('l1_ratio'), alpha = best.best_params_.get('alpha')).fit(train_x,train_y)\n",
    "            \n",
    "        y_pred = best_model.predict(test_x)\n",
    "        RMSE = (math.sqrt(mean_squared_error(y_pred, test_y)))\n",
    "        print(RMSE)\n",
    "        RMSE_all.append(RMSE)\n",
    "        \n",
    "    print(min(RMSE_all))\n",
    "    print(' ')\n",
    "    return RMSE_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33a207b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_result(train_list,test_list):\n",
    "    print('Result of SVR')\n",
    "    RMSE_all = []\n",
    "    for i in range(0,len(train_list)):\n",
    "        print('Criterion ' + str(i+1) + ': ')\n",
    "        train = train_list[i]\n",
    "        test = test_list[i]\n",
    "            \n",
    "        train_x = train.iloc[:,:(train.shape[1] - 1)]\n",
    "        train_y = train.iloc[:,-1:]\n",
    "            \n",
    "        test_x = test.iloc[:,:(test.shape[1] - 1)]\n",
    "        test_y = test.iloc[:,-1:]\n",
    "            \n",
    "        regressor = SVR(kernel='rbf')\n",
    "        model = TransformedTargetRegressor(regressor= regressor,\n",
    "                                        transformer = MinMaxScaler()\n",
    "                                        ).fit(train_x,train_y)\n",
    "        y_pred = model.predict(test_x)\n",
    "            \n",
    "        RMSE = (math.sqrt(mean_squared_error(y_pred, test_y)))\n",
    "        print(RMSE)\n",
    "        RMSE_all.append(RMSE)\n",
    "        \n",
    "    print(min(RMSE_all))\n",
    "    print(' ')\n",
    "    return RMSE_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6809705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GALS(data,target):\n",
    "    \n",
    "    training_data,testing_data = train_test_split(data, 0.7)\n",
    "    \n",
    "    train_preprocessed = data_shift(training_data,target)\n",
    "    test_preprocessed = data_shift(testing_data,target)\n",
    "    \n",
    "    X, y = feature_space_generator(train_preprocessed, max_lag)\n",
    "    test_X, test_y = feature_space_generator(test_preprocessed, max_lag)\n",
    "    \n",
    "    best_list,score_list = multi_lag_selection(sim_list,rel_list,X,y)\n",
    "    \n",
    "    train_list = generate_list(X, y, best_list)\n",
    "    test_list = generate_list(test_X, test_y, best_list)\n",
    "    \n",
    "    RMSE_LR = linear_regression_result(train_list,test_list)\n",
    "    RMSE_RF = random_forest_result(train_list,test_list)\n",
    "    RMSE_EN = elastic_net_result(train_list,test_list)\n",
    "    RMSE_SVR = svr_result(train_list,test_list)\n",
    "    \n",
    "    return RMSE_LR, RMSE_RF,RMSE_EN,RMSE_SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb09ed88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correl correl\n",
      "iteration: 1, number of features: 79, score: 4968.263\n",
      "iteration: 1, number of features: 79, score: 4809.919\n",
      "iteration: 1, number of features: 71, score: 4063.565\n",
      "iteration: 4, number of features: 69, score: 3658.786\n",
      "iteration: 5, number of features: 67, score: 3243.590\n",
      "iteration: 6, number of features: 65, score: 3200.759\n",
      "iteration: 7, number of features: 56, score: 2547.110\n",
      "iteration: 10, number of features: 56, score: 2542.245\n",
      "iteration: 11, number of features: 60, score: 2508.007\n",
      "iteration: 11, number of features: 54, score: 2347.374\n",
      "iteration: 11, number of features: 55, score: 2234.674\n",
      "iteration: 12, number of features: 51, score: 1871.922\n",
      "iteration: 15, number of features: 50, score: 1747.302\n",
      "iteration: 16, number of features: 49, score: 1665.373\n",
      "iteration: 22, number of features: 50, score: 1625.726\n",
      "iteration: 26, number of features: 46, score: 1475.172\n",
      "iteration: 27, number of features: 44, score: 1445.796\n",
      "iteration: 29, number of features: 42, score: 1385.983\n",
      "iteration: 41, number of features: 41, score: 1305.293\n",
      "iteration: 45, number of features: 37, score: 1073.336\n",
      "iteration: 48, number of features: 38, score: 1026.403\n",
      "iteration: 224, number of features: 34, score: 955.751\n",
      "correl mi\n",
      "iteration: 1, number of features: 85, score: 5665.651\n",
      "iteration: 1, number of features: 84, score: 5517.703\n",
      "iteration: 1, number of features: 78, score: 4439.855\n",
      "iteration: 2, number of features: 75, score: 4340.133\n",
      "iteration: 2, number of features: 69, score: 4019.300\n",
      "iteration: 3, number of features: 71, score: 3902.830\n",
      "iteration: 4, number of features: 67, score: 3428.463\n",
      "iteration: 5, number of features: 67, score: 3242.747\n",
      "iteration: 6, number of features: 64, score: 3217.679\n",
      "iteration: 6, number of features: 64, score: 3083.786\n",
      "iteration: 7, number of features: 61, score: 2833.709\n",
      "iteration: 8, number of features: 56, score: 2660.394\n",
      "iteration: 9, number of features: 55, score: 2444.168\n",
      "iteration: 10, number of features: 53, score: 2361.173\n",
      "iteration: 11, number of features: 53, score: 2206.905\n",
      "iteration: 12, number of features: 55, score: 2084.997\n",
      "iteration: 12, number of features: 52, score: 2011.020\n",
      "iteration: 15, number of features: 51, score: 1968.040\n",
      "iteration: 16, number of features: 52, score: 1958.824\n",
      "iteration: 17, number of features: 50, score: 1930.407\n",
      "iteration: 17, number of features: 51, score: 1740.102\n",
      "iteration: 18, number of features: 47, score: 1734.150\n",
      "iteration: 21, number of features: 45, score: 1571.104\n",
      "iteration: 22, number of features: 43, score: 1417.706\n",
      "iteration: 51, number of features: 43, score: 1329.304\n",
      "iteration: 73, number of features: 45, score: 1328.348\n",
      "iteration: 81, number of features: 43, score: 1298.509\n",
      "iteration: 82, number of features: 39, score: 1033.035\n",
      "iteration: 224, number of features: 39, score: 1025.540\n",
      "correl pcor\n",
      "iteration: 1, number of features: 79, score: 4957.031\n",
      "iteration: 1, number of features: 77, score: 4926.592\n",
      "iteration: 2, number of features: 75, score: 4668.376\n",
      "iteration: 2, number of features: 74, score: 4513.650\n",
      "iteration: 2, number of features: 74, score: 4440.203\n",
      "iteration: 3, number of features: 74, score: 4359.408\n",
      "iteration: 4, number of features: 69, score: 4019.210\n",
      "iteration: 4, number of features: 68, score: 3697.170\n",
      "iteration: 5, number of features: 65, score: 3259.970\n",
      "iteration: 6, number of features: 64, score: 3156.840\n",
      "iteration: 7, number of features: 61, score: 3015.101\n",
      "iteration: 7, number of features: 61, score: 2892.775\n",
      "iteration: 8, number of features: 58, score: 2636.208\n",
      "iteration: 9, number of features: 56, score: 2611.293\n",
      "iteration: 10, number of features: 58, score: 2526.887\n",
      "iteration: 10, number of features: 54, score: 2464.287\n",
      "iteration: 11, number of features: 58, score: 2430.674\n",
      "iteration: 14, number of features: 54, score: 2188.579\n",
      "iteration: 15, number of features: 51, score: 2133.513\n",
      "iteration: 16, number of features: 53, score: 1966.981\n",
      "iteration: 18, number of features: 48, score: 1759.869\n",
      "iteration: 22, number of features: 49, score: 1715.990\n",
      "iteration: 23, number of features: 50, score: 1666.052\n",
      "iteration: 26, number of features: 43, score: 1221.149\n",
      "iteration: 35, number of features: 39, score: 1133.963\n",
      "iteration: 120, number of features: 41, score: 1021.009\n",
      "iteration: 240, number of features: 39, score: 996.792\n",
      "mi correl\n",
      "iteration: 1, number of features: 88, score: 56138.677\n",
      "iteration: 1, number of features: 88, score: 56052.767\n",
      "iteration: 1, number of features: 82, score: 48632.020\n",
      "iteration: 1, number of features: 81, score: 47545.127\n",
      "iteration: 1, number of features: 75, score: 40607.436\n",
      "iteration: 2, number of features: 74, score: 39530.530\n",
      "iteration: 2, number of features: 72, score: 37436.469\n",
      "iteration: 3, number of features: 66, score: 31391.905\n",
      "iteration: 4, number of features: 65, score: 30446.263\n",
      "iteration: 6, number of features: 64, score: 29505.618\n",
      "iteration: 6, number of features: 59, score: 25025.461\n",
      "iteration: 7, number of features: 57, score: 23357.249\n",
      "iteration: 8, number of features: 55, score: 21780.595\n",
      "iteration: 9, number of features: 53, score: 20200.998\n",
      "iteration: 13, number of features: 50, score: 17938.154\n",
      "iteration: 14, number of features: 48, score: 16537.990\n",
      "iteration: 18, number of features: 48, score: 16535.646\n",
      "iteration: 18, number of features: 47, score: 15819.371\n",
      "iteration: 20, number of features: 45, score: 14514.123\n",
      "iteration: 24, number of features: 45, score: 14470.201\n",
      "iteration: 24, number of features: 44, score: 13830.266\n",
      "iteration: 27, number of features: 43, score: 13232.384\n",
      "iteration: 37, number of features: 41, score: 12022.677\n",
      "iteration: 37, number of features: 41, score: 12010.694\n",
      "iteration: 59, number of features: 37, score: 9756.530\n",
      "iteration: 157, number of features: 31, score: 6791.848\n",
      "mi mi\n",
      "iteration: 1, number of features: 90, score: 58689.819\n",
      "iteration: 1, number of features: 88, score: 56115.330\n",
      "iteration: 1, number of features: 82, score: 48683.485\n",
      "iteration: 1, number of features: 81, score: 47435.758\n",
      "iteration: 1, number of features: 74, score: 39595.630\n",
      "iteration: 2, number of features: 74, score: 39553.461\n",
      "iteration: 2, number of features: 74, score: 39549.283\n",
      "iteration: 2, number of features: 68, score: 33285.780\n",
      "iteration: 4, number of features: 65, score: 30465.055\n",
      "iteration: 5, number of features: 65, score: 30462.140\n",
      "iteration: 5, number of features: 61, score: 26796.774\n",
      "iteration: 6, number of features: 58, score: 24176.192\n",
      "iteration: 8, number of features: 57, score: 23321.731\n",
      "iteration: 9, number of features: 56, score: 22524.633\n",
      "iteration: 9, number of features: 54, score: 20943.979\n",
      "iteration: 10, number of features: 52, score: 19394.923\n",
      "iteration: 11, number of features: 51, score: 18649.258\n",
      "iteration: 12, number of features: 50, score: 17939.445\n",
      "iteration: 13, number of features: 49, score: 17207.831\n",
      "iteration: 13, number of features: 45, score: 14467.294\n",
      "iteration: 21, number of features: 43, score: 13205.975\n",
      "iteration: 55, number of features: 40, score: 11416.637\n",
      "iteration: 62, number of features: 39, score: 10842.730\n",
      "iteration: 92, number of features: 38, score: 10289.163\n",
      "iteration: 93, number of features: 37, score: 9741.830\n",
      "iteration: 98, number of features: 36, score: 9215.929\n",
      "mi pcor\n",
      "iteration: 1, number of features: 82, score: 48640.674\n",
      "iteration: 1, number of features: 78, score: 43990.037\n",
      "iteration: 1, number of features: 77, score: 42864.859\n",
      "iteration: 1, number of features: 77, score: 42803.592\n",
      "iteration: 2, number of features: 76, score: 41766.431\n",
      "iteration: 2, number of features: 76, score: 41701.327\n",
      "iteration: 2, number of features: 75, score: 40713.679\n",
      "iteration: 2, number of features: 70, score: 35339.685\n",
      "iteration: 2, number of features: 69, score: 34327.232\n",
      "iteration: 4, number of features: 63, score: 28601.575\n",
      "iteration: 5, number of features: 61, score: 26800.212\n",
      "iteration: 6, number of features: 60, score: 25905.825\n",
      "iteration: 7, number of features: 55, score: 21746.943\n",
      "iteration: 9, number of features: 54, score: 20914.704\n",
      "iteration: 14, number of features: 51, score: 18684.425\n",
      "iteration: 15, number of features: 51, score: 18666.882\n",
      "iteration: 15, number of features: 50, score: 17963.219\n",
      "iteration: 17, number of features: 49, score: 17232.119\n",
      "iteration: 18, number of features: 49, score: 17209.263\n",
      "iteration: 21, number of features: 48, score: 16471.813\n",
      "iteration: 21, number of features: 47, score: 15865.606\n",
      "iteration: 22, number of features: 47, score: 15861.513\n",
      "iteration: 22, number of features: 45, score: 14524.323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 33, number of features: 45, score: 14493.322\n",
      "iteration: 37, number of features: 44, score: 13832.659\n",
      "iteration: 38, number of features: 42, score: 12585.125\n",
      "iteration: 44, number of features: 40, score: 11405.487\n",
      "iteration: 62, number of features: 39, score: 10845.592\n",
      "iteration: 135, number of features: 39, score: 10826.019\n",
      "iteration: 144, number of features: 38, score: 10310.054\n",
      "iteration: 147, number of features: 38, score: 10308.290\n",
      "iteration: 148, number of features: 37, score: 9776.338\n",
      "iteration: 181, number of features: 37, score: 9743.489\n",
      "iteration: 201, number of features: 37, score: 9736.806\n",
      "iteration: 224, number of features: 34, score: 8214.353\n",
      "Result of Linear Regression\n",
      "Criterion 1: \n",
      "7.667561752409476\n",
      "Criterion 2: \n",
      "4.882208272283286\n",
      "Criterion 3: \n",
      "6.344496637066148\n",
      "Criterion 4: \n",
      "4.811976163596782\n",
      "Criterion 5: \n",
      "8.989843858671726\n",
      "Criterion 6: \n",
      "7.900788888644357\n",
      "4.811976163596782\n",
      " \n",
      "Result of Random Forest\n",
      "Criterion 1: \n",
      "106.99350088592182\n",
      "Criterion 2: \n",
      "103.76948845843906\n",
      "Criterion 3: \n",
      "103.95339201390173\n",
      "Criterion 4: \n",
      "100.36632997743602\n",
      "Criterion 5: \n",
      "108.79091567411676\n",
      "Criterion 6: \n",
      "105.86990984952276\n",
      "100.36632997743602\n",
      " \n",
      "Result of elastic net\n",
      "Criterion 1: \n",
      "7.542700158494654\n",
      "Criterion 2: \n",
      "5.025909473383226\n",
      "Criterion 3: \n",
      "6.290554341684948\n",
      "Criterion 4: \n",
      "4.80466535386618\n",
      "Criterion 5: \n",
      "8.932729265659344\n",
      "Criterion 6: \n",
      "7.911806441980982\n",
      "4.80466535386618\n",
      " \n",
      "Result of SVR\n",
      "Criterion 1: \n",
      "150.90136277651322\n",
      "Criterion 2: \n",
      "146.4223085748675\n",
      "Criterion 3: \n",
      "146.77613584709522\n",
      "Criterion 4: \n",
      "153.0243167233219\n",
      "Criterion 5: \n",
      "151.3456719826537\n",
      "Criterion 6: \n",
      "149.86452717615055\n",
      "146.4223085748675\n",
      " \n"
     ]
    }
   ],
   "source": [
    "RMSE_LR, RMSE_RF,RMSE_EN,RMSE_SVR= GALS(data,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
